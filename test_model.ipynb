{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "572dcdfd",
   "metadata": {},
   "source": [
    "# * Import needed modules, for local and for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01b63d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import system libs\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import pathlib\n",
    "import itertools\n",
    "\n",
    "# Import data handling libs\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Import machine learning libs\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa67b214",
   "metadata": {},
   "source": [
    "# Load dataset as generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cab3f0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = f'./DATASET/train'\n",
    "VALIDATION_DIR = f'./DATASET/validation'\n",
    "TEST_DIR = f'./DATASET/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c5e8048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\"\"\"\n",
    "On this project, generator were used to handle RAM usage crash.\n",
    "It basically load one batch at a time from the dataframe instead of loading all at once\n",
    "to speedup training.\n",
    "\"\"\"\n",
    "\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16\n",
    "LABEL_MODE = 'categorical'\n",
    "COLOR_MODE = 'rgb'  # accepts 'grayscale', 'rgb', and 'rgba' only\n",
    "SEED = 42\n",
    "\n",
    "def preprocess(image):\n",
    "    \"\"\"\n",
    "    Preprocessing function: Resize and normalize the images\n",
    "    PREPROCESS_INPUT_MODE_DOC =\n",
    "    mode: One of \"caffe\", \"tf\" or \"torch\".\n",
    "      - caffe: will convert the images from RGB to BGR,\n",
    "          then will zero-center each color channel with\n",
    "          respect to the ImageNet dataset,\n",
    "          without scaling.\n",
    "      - tf: will scale pixels between -1 and 1,\n",
    "          sample-wise.\n",
    "      - torch: will scale pixels between 0 and 1 and then\n",
    "          will normalize each channel with respect to the\n",
    "          ImageNet dataset.\n",
    "      Defaults to `\"caffe\"`.\n",
    "\n",
    "      Note: each Keras Application expects a specific kind of input preprocessing.\n",
    "      For MobileNetV3, by default input preprocessing is included as a part of the\n",
    "      model (as a `Rescaling` layer), and thus\n",
    "      `keras.applications.mobilenet_v3.preprocess_input` is actually a\n",
    "      pass-through function. In this use case, MobileNetV3 models expect their\n",
    "      inputs to be float tensors of pixels with values in the `[0-255]` range.\n",
    "      At the same time, preprocessing as a part of the model (i.e. `Rescaling`\n",
    "      layer) can be disabled by setting `include_preprocessing` argument to `False`.\n",
    "      With preprocessing disabled MobileNetV3 models expect their inputs to be float\n",
    "      tensors of pixels with values in the `[-1, 1]` range.\n",
    "    \"\"\"\n",
    "    # # image = tf.image.resize(image, (224, 224), preserve_aspect_ratio=True)  # Resize to 224x224\n",
    "    # image = tf.cast(image, tf.float32)  # Convert to float32\n",
    "    # image = (image / 127.5) - 1  # Normalize to [-1, 1] range\n",
    "    return image\n",
    "\n",
    "def create_gens():\n",
    "    \"\"\" Function to load from pre-split dataset directories using ImageDataGenerator with preprocessing \"\"\"\n",
    "    # Test Batch Size\n",
    "    \n",
    "\n",
    "    # Initialize the ImageDataGenerator without validation split but with preprocessing function\n",
    "    tr_gen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "    ts_gen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess\n",
    "    )\n",
    "\n",
    "    # Train Generator (from the pre-split training directory)\n",
    "    train_generator = tr_gen.flow_from_directory(\n",
    "        TRAIN_DIR,\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=LABEL_MODE,\n",
    "        color_mode=COLOR_MODE,\n",
    "        seed=SEED,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # Validation Generator (from the pre-split validation directory)\n",
    "    validation_generator = ts_gen.flow_from_directory(\n",
    "        VALIDATION_DIR,\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=LABEL_MODE,\n",
    "        color_mode=COLOR_MODE,\n",
    "        seed=SEED,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # Test Generator (from the pre-split test directory)\n",
    "    test_generator = ts_gen.flow_from_directory(\n",
    "        TEST_DIR,\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode=LABEL_MODE,\n",
    "        color_mode=COLOR_MODE,\n",
    "        seed=SEED,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_generator, validation_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f695a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14814 images belonging to 4 classes.\n",
      "Found 4252 images belonging to 4 classes.\n",
      "Found 2099 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Create datasets \"\"\"\n",
    "train_gen, val_gen, test_gen = create_gens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f88d0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'COVID': 0, 'Lung_Opacity': 1, 'Normal': 2, 'Viral Pneumonia': 3}\n"
     ]
    }
   ],
   "source": [
    "print(train_gen.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb1cea6",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e26b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = f'MODELS\\mobilenetv3small\\mobilenetv3small-COVID-19-94.90.keras'\n",
    "model = tf.keras.models.load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8a33f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2099/2099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 24ms/step - accuracy: 0.9489 - loss: 0.2835   \n",
      "Test Loss:  0.28275734186172485\n",
      "Test Accuracy:  0.9490233659744263\n"
     ]
    }
   ],
   "source": [
    "ts_length = test_gen.samples\n",
    "test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n",
    "test_steps = ts_length // test_batch_size\n",
    "\n",
    "# train_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\n",
    "# valid_score = model.evaluate(val_gen, steps= test_steps, verbose= 1)\n",
    "test_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n",
    "\n",
    "# print(\"Train Loss: \", train_score[0])\n",
    "# print(\"Train Accuracy: \", train_score[1])\n",
    "# print('-' * 20)\n",
    "# print(\"Validation Loss: \", valid_score[0])\n",
    "# print(\"Validation Accuracy: \", valid_score[1])\n",
    "# print('-' * 20)\n",
    "print(\"Test Loss: \", test_score[0])\n",
    "print(\"Test Accuracy: \", test_score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
